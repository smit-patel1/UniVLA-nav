# UniVLA-nav is a system for deploying a Vision-Language-Action model (UniVLA).

# The Jetson Orin Nano runs all real-time robotics components, including ROS2, sensors, state estimation, and control logic.
 
# A university GPU cluster runs UniVLA as a remote inference service. The Jetson sends observations and task context to the service and receives high-level action outputs.
